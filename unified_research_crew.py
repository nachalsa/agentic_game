"""
í†µí•©ëœ AI ë¦¬ì„œì¹˜ í¬ë£¨ - study.py ê¸°ë°˜ìœ¼ë¡œ ê°œì„ ëœ ë²„ì „
- improved_research_crew.py
- korean_optimized_crew.py  
- fixed_search_tool.py
ì˜ ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í˜•íƒœë¡œ êµ¬ì„±
"""
import os
import sys
import logging
import argparse
import re
import hashlib
from datetime import datetime
from typing import Set, List, Dict, Any
import litellm
from crewai import Agent, Task, Crew, Process
from crewai.tools import tool
from dotenv import load_dotenv

# DuckDuckGo Search
from ddgs import DDGS

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'unified_research_crew_{datetime.now().strftime("%Y%m%d")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# í™˜ê²½ ì„¤ì •
load_dotenv()
os.environ.setdefault("OTEL_SDK_DISABLED", "true")
os.environ.setdefault("CREWAI_DISABLE_TELEMETRY", "true")

# í™˜ê²½ ë³€ìˆ˜
MODEL_NAME = os.getenv("DEFAULT_LLM", "mistral-small3.2")
API_BASE_URL = os.getenv("DEFAULT_URL", "http://192.168.100.26:11434")
API_KEY = os.getenv("DEFAULT_API_KEY", "ollama")
MAX_EXECUTION_TIME = int(os.getenv("MAX_EXECUTION_TIME", "600"))

if not API_BASE_URL.endswith('/v1'):
    API_BASE_URL = API_BASE_URL.rstrip('/') + '/v1'

# ì„¤ì • í´ë˜ìŠ¤
class ResearchConfig:
    """ë¦¬ì„œì¹˜ ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 topic: str,
                 search_queries_count: int = 5,
                 word_count_range: tuple = (700, 900),
                 language: str = "í•œêµ­ì–´",
                 report_type: str = "ë¸”ë¡œê·¸",
                 quality_mode: str = "standard"):  # standard, korean_optimized
        self.topic = topic
        self.search_queries_count = search_queries_count
        self.word_count_range = word_count_range
        self.language = language
        self.report_type = report_type
        self.quality_mode = quality_mode
        
        # íŒŒì¼ëª…ìš© ì•ˆì „í•œ í† í”½ëª… ìƒì„±
        self.safe_topic = re.sub(r'[^\w\s-]', '', topic.replace(' ', '_'))[:50]

# ê°œì„ ëœ ì›¹ ê²€ìƒ‰ ë„êµ¬ (fixed_search_tool.py ê¸°ë°˜)
_search_history: Set[str] = set()
_search_results_cache: Dict[str, str] = {}

def clear_search_history():
    """ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
    global _search_history, _search_results_cache
    _search_history.clear()
    _search_results_cache.clear()

def get_query_hash(query: str) -> str:
    """ì¿¼ë¦¬ì˜ í•´ì‹œê°’ ìƒì„± (ìœ ì‚¬í•œ ì¿¼ë¦¬ ê°ì§€ìš©)"""
    normalized_query = query.lower().strip()
    return hashlib.md5(normalized_query.encode()).hexdigest()

@tool("Web Search Tool")
def improved_web_search_tool(query: str) -> str:
    """ê°œì„ ëœ ì›¹ ê²€ìƒ‰ ë„êµ¬ - ì¤‘ë³µ ë°©ì§€ ë° ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”"""
    
    # ì…ë ¥ ê²€ì¦
    if not query or not isinstance(query, str):
        return "âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ê²€ìƒ‰ ì¿¼ë¦¬ì…ë‹ˆë‹¤."
    
    query = query.strip()
    if len(query) < 3:
        return "âŒ ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ 3ê¸€ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    # ì¿¼ë¦¬ í•´ì‹œ ìƒì„±
    query_hash = get_query_hash(query)
    
    # ì¤‘ë³µ ê²€ìƒ‰ ë°©ì§€
    if query_hash in _search_history:
        if query_hash in _search_results_cache:
            return f"ğŸ”„ (ìºì‹œë¨) {_search_results_cache[query_hash]}"
        else:
            return f"âš ï¸ ì´ë¯¸ ê²€ìƒ‰í•œ ì¿¼ë¦¬ì…ë‹ˆë‹¤: '{query}'. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
    
    # ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    _search_history.add(query_hash)
    
    try:
        logger.info(f"ğŸ” ì›¹ ê²€ìƒ‰ ì‹œì‘: '{query}'")
        
        # DuckDuckGo ê²€ìƒ‰ ì‹¤í–‰
        ddgs = DDGS()
        results = ddgs.text(
            query=query, 
            region='wt-wt', 
            safesearch='moderate', 
            max_results=5
        )
        
        if not results:
            error_msg = f"âš ï¸ '{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            logger.warning(error_msg)
            return error_msg
        
        # ê²°ê³¼ í¬ë§¤íŒ…
        formatted_results = format_search_results(query, results)
        
        # ìºì‹œì— ì €ì¥
        _search_results_cache[query_hash] = formatted_results
        
        logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
        return formatted_results
        
    except Exception as e:
        error_msg = f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(f"ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜ - Query: '{query}', Error: {e}")
        
        # DNS ì˜¤ë¥˜ ë“± ë„¤íŠ¸ì›Œí¬ ë¬¸ì œì¸ ê²½ìš° ëŒ€ì²´ ë©”ì‹œì§€
        if "dns error" in str(e).lower() or "name or service not known" in str(e).lower():
            error_msg += "\nğŸŒ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        return error_msg

def format_search_results(query: str, results: List[Dict[str, Any]]) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§¤íŒ…"""
    formatted = f"ğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼:\n\n"
    
    # ì¤‘ë³µ URL ì œê±°
    seen_urls = set()
    unique_results = []
    
    for result in results:
        url = result.get('href', '')
        if url and url not in seen_urls:
            unique_results.append(result)
            seen_urls.add(url)
    
    if not unique_results:
        return f"âš ï¸ '{query}'ì— ëŒ€í•œ ìœ íš¨í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    for i, result in enumerate(unique_results, 1):
        title = result.get('title', 'ì œëª© ì—†ìŒ')
        body = result.get('body', 'ì„¤ëª… ì—†ìŒ')
        href = result.get('href', '#')
        
        # ë³¸ë¬¸ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
        if len(body) > 150:
            body = body[:150] + '...'
            
        formatted += f"{i}. **{title}**\n"
        formatted += f"   ğŸ“„ {body}\n"
        formatted += f"   ğŸ”— {href}\n\n"
    
    return formatted

# ì£¼ì œë³„ í”„ë¦¬ì…‹
RESEARCH_PRESETS = {
    "ai": "2025ë…„ ìµœì‹  AI íŠ¸ë Œë“œ",
    "blockchain": "2025ë…„ ë¸”ë¡ì²´ì¸ ê¸°ìˆ  ë°œì „", 
    "climate": "ì§€ì†ê°€ëŠ¥í•œ ê¸°í›„ ê¸°ìˆ  í˜ì‹ ",
    "health": "ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ ê¸°ìˆ  íŠ¸ë Œë“œ",
    "fintech": "í•€í…Œí¬ ì‚°ì—… ìµœì‹  ë™í–¥",
    "architecture": "í˜„ëŒ€ ê±´ì¶• ê¸°ìˆ  í˜ì‹ ",
    "education": "êµìœ¡ ê¸°ìˆ  ë””ì§€í„¸ ì „í™˜",
    "energy": "ì¬ìƒ ì—ë„ˆì§€ ê¸°ìˆ  ë°œì „",
    "space": "ìš°ì£¼ ê¸°ìˆ  ë° íƒì‚¬ ë™í–¥",
    "food": "í‘¸ë“œí…Œí¬ ì‚°ì—… í˜ì‹ "
}

def get_preset_topic(preset_name: str) -> str:
    """í”„ë¦¬ì…‹ ì£¼ì œ ë°˜í™˜ (ì—†ìœ¼ë©´ ì…ë ¥ê°’ ê·¸ëŒ€ë¡œ ë°˜í™˜)"""
    return RESEARCH_PRESETS.get(preset_name.lower(), preset_name)

# ë²”ìš© AI ë¦¬ì„œì¹˜ í¬ë£¨ í´ë˜ìŠ¤
class UnifiedResearchCrew:
    """í†µí•©ëœ AI ë¦¬ì„œì¹˜ í¬ë£¨ ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: ResearchConfig):
        self.config = config
        self.setup_environment()
    
    def setup_environment(self):
        """LiteLLM í™˜ê²½ ì„¤ì •"""
        litellm.api_base = API_BASE_URL
        litellm.api_key = API_KEY
        litellm.drop_params = True
        logger.info("í™˜ê²½ ì„¤ì • ì™„ë£Œ")
    
    def create_agents(self):
        """ì—ì´ì „íŠ¸ ìƒì„± (í’ˆì§ˆ ëª¨ë“œì— ë”°ë¼ ë‹¤ë¦„)"""
        
        planner = Agent(
            role='ì—°êµ¬ ê³„íš ì „ë¬¸ê°€',
            goal=f'{self.config.topic}ì— ëŒ€í•œ íš¨ê³¼ì ì¸ ì›¹ ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½',
            backstory='''ë‹¤ì–‘í•œ ì£¼ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì „ëµê°€ì…ë‹ˆë‹¤. 
            ë³µì¡í•œ ì£¼ì œë¥¼ í•µì‹¬ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´í•˜ê³ , ìµœì‹  ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆëŠ” ê²€ìƒ‰ì–´ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤.''',
            verbose=True,
            allow_delegation=False,
            llm=f"openai/{MODEL_NAME}",
            max_tokens=1024,
            temperature=0.6
        )

        researcher = Agent(
            role='ì „ë¬¸ ë¦¬ì„œì¹˜ ë¶„ì„ê°€',
            goal=f'{self.config.topic}ì— ëŒ€í•œ ì¢…í•©ì ì´ê³  ì‹¬ì¸µì ì¸ ì •ë³´ ìˆ˜ì§‘ ë° ë¶„ì„',
            backstory='''ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì‹¤ì‹œê°„ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ , ë‹¤ì–‘í•œ ì¶œì²˜ì˜ ì •ë³´ë¥¼ ë¹„íŒì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ 
            ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ëŠ” ìˆ™ë ¨ëœ ì—°êµ¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.''',
            verbose=True,
            allow_delegation=False,
            tools=[improved_web_search_tool],
            llm=f"openai/{MODEL_NAME}",
            max_tokens=2000,
            temperature=0.7
        )

        # í’ˆì§ˆ ëª¨ë“œì— ë”°ë¥¸ ì‘ê°€ ì—ì´ì „íŠ¸ ìƒì„±
        if self.config.quality_mode == "korean_optimized":
            writer = self._create_korean_optimized_writer()
        else:
            writer = self._create_standard_writer()
        
        return planner, researcher, writer
    
    def _create_standard_writer(self):
        """í‘œì¤€ ì½˜í…ì¸  ì‘ì„± ì—ì´ì „íŠ¸"""
        return Agent(
            role='ì „ë¬¸ ì½˜í…ì¸  ì‘ê°€',
            goal=f'{self.config.topic}ì— ëŒ€í•œ ë§¤ë ¥ì ì´ê³  ìœ ìµí•œ {self.config.report_type} ì‘ì„±',
            backstory=f'''ë³µì¡í•œ ì •ë³´ë¥¼ {self.config.language}ë¡œ ëª…í™•í•˜ê³  ë§¤ë ¥ì ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤. 
            ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ìµœì‹  ì •ë³´ë¥¼ ë…ìê°€ ì´í•´í•˜ê¸° ì‰½ê³  ì‹¤ìš©ì ì¸ ì½˜í…ì¸ ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.''',
            verbose=True,
            allow_delegation=False,
            llm=f"openai/{MODEL_NAME}",
            max_tokens=2000,
            temperature=0.8
        )
    
    def _create_korean_optimized_writer(self):
        """í•œêµ­ì–´ í’ˆì§ˆ ê°•í™”ëœ ì½˜í…ì¸  ì‘ì„± ì—ì´ì „íŠ¸"""
        return Agent(
            role='í•œêµ­ì–´ ì „ë¬¸ ì‘ê°€',
            goal=f'{self.config.topic}ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•œ í•œêµ­ì–´ ë¸”ë¡œê·¸ ì‘ì„±',
            backstory='''í•œêµ­ì–´ ì „ë¬¸ ì‘ê°€ë¡œì„œ ë³µì¡í•œ ê¸°ìˆ  ë‚´ìš©ì„ 
            ìì—°ìŠ¤ëŸ½ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í•œêµ­ì–´ë¡œ í‘œí˜„í•©ë‹ˆë‹¤. 
            ì˜ì–´ í‘œí˜„ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ìˆœìˆ˜ í•œêµ­ì–´ë§Œì„ ì‚¬ìš©í•˜ë©°,
            ì •í™•í•œ ì •ë³´ì™€ ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.''',
            verbose=True,
            allow_delegation=False,
            llm=f"openai/{MODEL_NAME}",
            max_tokens=2000,
            temperature=0.7  # ë” ë³´ìˆ˜ì ì¸ ì˜¨ë„
        )

    def create_tasks(self, planner, researcher, writer):
        """íƒœìŠ¤í¬ ìƒì„±"""
        
        # 1. ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½
        planning_task = Task(
            description=f'''"{self.config.topic}"ì— ëŒ€í•œ í¬ê´„ì ì¸ ì—°êµ¬ë¥¼ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.
            
            ì´ ì£¼ì œë¥¼ ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•˜ì—¬ {self.config.search_queries_count}ê°œì˜ êµ¬ì²´ì ì´ê³  íš¨ê³¼ì ì¸ ì˜ì–´ ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”:
            
            1. ìµœì‹  ë™í–¥ ë° ë°œì „ì‚¬í•­ (latest trends, developments, innovations)
            2. ì „ë¬¸ê°€ ë¶„ì„ ë° ì—°êµ¬ ê²°ê³¼ (expert analysis, research, studies)  
            3. ì‹¤ì œ ì ìš© ì‚¬ë¡€ ë° ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” (case studies, applications, examples)
            4. ë¯¸ë˜ ì „ë§ ë° ì˜ˆì¸¡ (future outlook, predictions, forecasts)
            5. ì‚°ì—…ë³„ ì˜í–¥ ë° í™œìš© (industry impact, implementation)
            
            **ì¤‘ìš”í•œ í˜•ì‹ ìš”êµ¬ì‚¬í•­:**
            - ê° ì¿¼ë¦¬ëŠ” ì„œë¡œ ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤
            - ì •í™•íˆ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
            SEARCH_QUERY_1: "ì²« ë²ˆì§¸ ê²€ìƒ‰ì–´"
            SEARCH_QUERY_2: "ë‘ ë²ˆì§¸ ê²€ìƒ‰ì–´"  
            SEARCH_QUERY_3: "ì„¸ ë²ˆì§¸ ê²€ìƒ‰ì–´"
            SEARCH_QUERY_4: "ë„¤ ë²ˆì§¸ ê²€ìƒ‰ì–´"
            SEARCH_QUERY_5: "ë‹¤ì„¯ ë²ˆì§¸ ê²€ìƒ‰ì–´"
            
            ê° ì¿¼ë¦¬ëŠ” ëª…í™•í•˜ê³  ë…ë¦½ì ìœ¼ë¡œ ê²€ìƒ‰ ê°€ëŠ¥í•´ì•¼ í•˜ë©°, 2024-2025ë…„ ìµœì‹  ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•˜ì„¸ìš”.''',
            
            expected_output=f'''ì •í™•íˆ ë‹¤ìŒ í˜•ì‹ì˜ {self.config.search_queries_count}ê°œ ì˜ì–´ ê²€ìƒ‰ ì¿¼ë¦¬:
            SEARCH_QUERY_1: "query1"
            SEARCH_QUERY_2: "query2"
            SEARCH_QUERY_3: "query3"
            SEARCH_QUERY_4: "query4"  
            SEARCH_QUERY_5: "query5"
            ì£¼ì œ: {self.config.topic}ì— ìµœì í™”ëœ ì„œë¡œ ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë“¤''',
            agent=planner
        )
        
        # 2. ì •ë³´ ìˆ˜ì§‘
        research_task = Task(
            description=f'''ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ëª©ë¡ì„ í™œìš©í•˜ì—¬ "{self.config.topic}"ì— ëŒ€í•œ ì‹¬ì¸µ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

            **í•„ìˆ˜ ìˆ˜í–‰ ì ˆì°¨:**
            1. ì´ì „ Task ê²°ê³¼ì—ì„œ "SEARCH_QUERY_1:", "SEARCH_QUERY_2:" ë“±ì˜ í˜•ì‹ìœ¼ë¡œ ëœ ê²€ìƒ‰ ì¿¼ë¦¬ë“¤ì„ ì°¾ì•„ ì¶”ì¶œí•©ë‹ˆë‹¤.
            2. ê° SEARCH_QUERY_Xì—ì„œ ë”°ì˜´í‘œ ì•ˆì˜ ê²€ìƒ‰ì–´ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
            3. ì¶”ì¶œëœ **ëª¨ë“  ê²€ìƒ‰ì–´ë¥¼ í•˜ë‚˜ì”© ìˆœì„œëŒ€ë¡œ** 'Web Search Tool'ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰í•©ë‹ˆë‹¤.
            4. ê²€ìƒ‰í•  ë•Œë§ˆë‹¤ "ğŸ” ê²€ìƒ‰ ì¤‘: X/5 - [ê²€ìƒ‰ì–´]" í˜•íƒœë¡œ ì§„í–‰ìƒí™©ì„ ì•Œë ¤ì£¼ì„¸ìš”.
            5. ë§Œì•½ ì–´ë–¤ ê²€ìƒ‰ì´ ì‹¤íŒ¨í•˜ê±°ë‚˜ ê´€ë ¨ì—†ëŠ” ê²°ê³¼ê°€ ë‚˜ì˜¤ë©´, í•´ë‹¹ ì£¼ì œì˜ ëŒ€ì²´ ê²€ìƒ‰ì–´ë¥¼ ë§Œë“¤ì–´ ë‹¤ì‹œ ê²€ìƒ‰í•˜ì„¸ìš”.
            
            **ë³´ê³ ì„œ ì‘ì„± ìš”êµ¬ì‚¬í•­:**
            ëª¨ë“  ê²€ìƒ‰ ì™„ë£Œ í›„, ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ í¬í•¨í•œ ì¢…í•© ë³´ê³ ì„œë¥¼ **ë°˜ë“œì‹œ {self.config.language}ë¡œ** ì‘ì„±í•˜ì„¸ìš”:
            - ì£¼ìš” íŠ¸ë Œë“œ ë° ë°œì „ì‚¬í•­
            - í•µì‹¬ í†µê³„ ë° ë°ì´í„°  
            - êµ¬ì²´ì  ì‚¬ë¡€ ë° ì‹¤ë¬´ ì ìš©
            - ì „ë¬¸ê°€ ì˜ê²¬ ë° ë¶„ì„
            - ë¯¸ë˜ ì „ë§
            
            **ì ˆëŒ€ì ìœ¼ë¡œ ì¤‘ìš”**: ê²€ìƒ‰ ê²°ê³¼ê°€ ì˜ì–´ë¡œ ë‚˜ì™€ë„ ë³´ê³ ì„œëŠ” **ë¬´ì¡°ê±´ {self.config.language}ë¡œë§Œ** ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.''',
            
            expected_output=f'''"{self.config.topic}"ì— ëŒ€í•œ ì£¼ìš” ì¸ì‚¬ì´íŠ¸, ìµœì‹  í†µê³„ ë° ì‹¤ì œ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ëŠ” 
            400-500ë‹¨ì–´ ë¶„ëŸ‰ì˜ ìƒì„¸í•œ ì—°êµ¬ ìš”ì•½ ë³´ê³ ì„œ (**ë°˜ë“œì‹œ {self.config.language}ë¡œ ì‘ì„±**).
            ëª¨ë“  ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ í†µí•´ ì–»ì€ ìµœì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±.''',
            
            agent=researcher,
            context=[planning_task]
        )

        # 3. ì½˜í…ì¸  ì‘ì„± (í’ˆì§ˆ ëª¨ë“œì— ë”°ë¼ ë‹¤ë¦„)
        if self.config.quality_mode == "korean_optimized":
            write_task = self._create_korean_optimized_task(writer, research_task)
        else:
            write_task = self._create_standard_task(writer, research_task)
        
        return [planning_task, research_task, write_task]
    
    def _create_standard_task(self, writer, research_task):
        """í‘œì¤€ ì‘ì„± íƒœìŠ¤í¬"""
        return Task(
            description=f'''ì—°êµ¬ ìš”ì•½ ë³´ê³ ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ "{self.config.topic}"ì— ëŒ€í•œ 
            **ë°˜ë“œì‹œ {self.config.language}ë¡œë§Œ ì‘ì„±ëœ** {self.config.report_type}ì„ ì‘ì„±í•©ë‹ˆë‹¤.
            
            **êµ¬ì²´ì  ìš”êµ¬ì‚¬í•­:**
            - ë¶„ëŸ‰: {self.config.word_count_range[0]}-{self.config.word_count_range[1]}ë‹¨ì–´
            - ë§¤ë ¥ì ì¸ {self.config.language} ì œëª©ê³¼ ë¶€ì œëª© ì‚¬ìš©
            - ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ {self.config.language} í‘œí˜„
            - ì—°êµ¬ ë³´ê³ ì„œì˜ ìµœì‹  ì •ë³´ë¥¼ ë°˜ì˜í•œ í˜„ì‹¤ì ì¸ ë‚´ìš©
            - ë…ìì˜ ê´€ì‹¬ì„ ë„ëŠ” êµ¬ì„±
            - ì‹¤ì œ ì‚¬ë¡€ë‚˜ êµ¬ì²´ì  ì˜ˆì‹œ í¬í•¨
            
            ëŒ€ìƒ ë…ì: í•´ë‹¹ ë¶„ì•¼ì— ê´€ì‹¬ìˆëŠ” ì¼ë°˜ì¸ ë° ì „ë¬¸ê°€''',
            
            expected_output=f'''ë…ì ì¹œí™”ì ì´ê³  ì •ë³´ê°€ í’ë¶€í•œ {self.config.word_count_range[0]}-{self.config.word_count_range[1]}ë‹¨ì–´ ë¶„ëŸ‰ì˜ 
            {self.config.report_type}. **ì™„ì „íˆ {self.config.language}ë¡œë§Œ ì‘ì„±**ë˜ì—ˆìœ¼ë©°, 
            ë™ì  ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°˜ì˜í•œ í˜„ì‹¤ì ì´ê³  ìœ ìš©í•œ ë‚´ìš© í¬í•¨.''',
            
            agent=writer,
            context=[research_task]
        )
    
    def _create_korean_optimized_task(self, writer, research_task):
        """í•œêµ­ì–´ ìµœì í™” ì‘ì„± íƒœìŠ¤í¬"""
        return Task(
            description=f'''
            ìˆ˜ì§‘ëœ ì—°êµ¬ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ "{self.config.topic}"ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¸”ë¡œê·¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
            
            **ì ˆëŒ€ ê·œì¹™:**
            1. ì˜ì–´ ë‹¨ì–´, ë¬¸ì¥, í‘œí˜„ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
            2. ëª¨ë“  ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”
            3. ì „ë¬¸ ìš©ì–´ë„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”
            
            **ê¸€ êµ¬ì¡°:**
            1. í¥ë¯¸ë¡œìš´ ì œëª© (í•œêµ­ì–´ë§Œ)
            2. ë§¤ë ¥ì ì¸ ë„ì…ë¶€ (200-300ì)
            3. ì£¼ìš” ë‚´ìš© (5-6ê°œ ì„¹ì…˜):
               - í˜„ì¬ ë™í–¥ê³¼ ë°œì „ ìƒí™©
               - í•µì‹¬ ê¸°ìˆ ê³¼ í˜ì‹  ë‚´ìš©
               - ì‹¤ì œ í™œìš© ì‚¬ë¡€ì™€ ì˜ˆì‹œ
               - ì£¼ìš” ê¸°ì—…ê³¼ ì‹œì¥ ë³€í™”
               - ë¯¸ë˜ ì „ë§ê³¼ ì˜ˆì¸¡
               - ê²°ë¡ ê³¼ ì‹œì‚¬ì 
            4. ë§ˆë¬´ë¦¬ ìš”ì•½ (150-200ì)
            
            **ì‘ì„± ê¸°ì¤€:**
            - ì´ 800-1000ë‹¨ì–´ (í•œêµ­ì–´ ê¸°ì¤€)
            - êµ¬ì²´ì ì¸ ë°ì´í„°ì™€ ì‚¬ë¡€ í¬í•¨
            - ì „ë¬¸ì ì´ì§€ë§Œ ì¼ë°˜ì¸ë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ë¬¸ì²´
            - ê° ì„¹ì…˜ì— ì ì ˆí•œ ì†Œì œëª© ì‚¬ìš©
            - ì‹¤ìš©ì ì´ê³  ìœ ìµí•œ ì •ë³´ ì œê³µ
            
            ë…ìê°€ ì£¼ì œë¥¼ ì™„ì „íˆ ì´í•´í•˜ê³  ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ ì‘ì„±í•˜ì„¸ìš”.
            ''',
            agent=writer,
            expected_output=f"{self.config.topic}ì— ëŒ€í•œ ê³ í’ˆì§ˆ ìˆœìˆ˜ í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ (800-1000ë‹¨ì–´)",
            context=[research_task]
        )
    
    def save_result(self, result):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if not result:
            logger.error("ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"research_report_{self.config.safe_topic}_{self.config.quality_mode}_{timestamp}.md"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"# {self.config.topic} ì—°êµ¬ ë³´ê³ ì„œ\n\n")
                f.write(f"**ìƒì„± ì‹œê°„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**í’ˆì§ˆ ëª¨ë“œ:** {self.config.quality_mode}\n")
                f.write(f"**ì–¸ì–´:** {self.config.language}\n\n")
                f.write("---\n\n")
                f.write(str(result))
            
            logger.info(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")
            return True
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def research(self):
        """ë©”ì¸ ë¦¬ì„œì¹˜ ì‹¤í–‰ ë©”ì„œë“œ"""
        try:
            logger.info(f"ğŸš€ '{self.config.topic}' ì—°êµ¬ ì‹œì‘ (ëª¨ë“œ: {self.config.quality_mode})")
            
            # ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
            clear_search_history()
            
            # ì—ì´ì „íŠ¸ ìƒì„±
            planner, researcher, writer = self.create_agents()
            
            # íƒœìŠ¤í¬ ìƒì„±
            tasks = self.create_tasks(planner, researcher, writer)
            
            # í¬ë£¨ ìƒì„± ë° ì‹¤í–‰
            crew = Crew(
                agents=[planner, researcher, writer],
                tasks=tasks,
                process=Process.sequential,
                verbose=True
            )
            
            result = crew.kickoff()
            
            # ê²°ê³¼ ì €ì¥
            if self.save_result(result):
                logger.info(f"âœ… '{self.config.topic}' ì—°êµ¬ ì™„ë£Œ")
                return result
            else:
                logger.error("âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨")
                return None
                
        except Exception as e:
            logger.error(f"âŒ ì—°êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - CLI ì¸í„°í˜ì´ìŠ¤ í¬í•¨"""
    parser = argparse.ArgumentParser(description='í†µí•© AI ë¦¬ì„œì¹˜ í¬ë£¨ - ëª¨ë“  ì£¼ì œì— ëŒ€í•œ ë³´ê³ ì„œ ìƒì„±')
    parser.add_argument('--topic', '-t', 
                        default='2025ë…„ ìµœì‹  AI íŠ¸ë Œë“œ', 
                        help='ì—°êµ¬ ì£¼ì œ (ë˜ëŠ” í”„ë¦¬ì…‹: ai, blockchain, health, etc.)')
    parser.add_argument('--queries', '-q', 
                        type=int, default=5, 
                        help='ê²€ìƒ‰ ì¿¼ë¦¬ ê°œìˆ˜ (ê¸°ë³¸ê°’: 5)')
    parser.add_argument('--words', '-w', 
                        default='700,900', 
                        help='ë‹¨ì–´ ìˆ˜ ë²”ìœ„ (ì˜ˆ: 700,900)')
    parser.add_argument('--type', '-r', 
                        default='ë¸”ë¡œê·¸', 
                        help='ë³´ê³ ì„œ ìœ í˜• (ë¸”ë¡œê·¸, ë³´ê³ ì„œ, ë¶„ì„ì„œ ë“±)')
    parser.add_argument('--language', '-l', 
                        default='í•œêµ­ì–´', 
                        help='ì¶œë ¥ ì–¸ì–´')
    parser.add_argument('--quality', '-m',
                        choices=['standard', 'korean_optimized'],
                        default='standard',
                        help='í’ˆì§ˆ ëª¨ë“œ (standard: í‘œì¤€, korean_optimized: í•œêµ­ì–´ ìµœì í™”)')
    parser.add_argument('--list-presets', 
                        action='store_true', 
                        help='ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¦¬ì…‹ ì£¼ì œ ëª©ë¡ ì¶œë ¥')
    
    args = parser.parse_args()
    
    # í”„ë¦¬ì…‹ ëª©ë¡ ì¶œë ¥
    if args.list_presets:
        print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¦¬ì…‹ ì£¼ì œ:")
        for key, value in RESEARCH_PRESETS.items():
            print(f"  {key}: {value}")
        return
    
    # ì„¤ì • ìƒì„±
    try:
        word_range = tuple(map(int, args.words.split(',')))
        if len(word_range) != 2:
            raise ValueError()
    except:
        word_range = (700, 900)
        print("âš ï¸ ë‹¨ì–´ ìˆ˜ í˜•ì‹ ì˜¤ë¥˜. ê¸°ë³¸ê°’ (700,900) ì‚¬ìš©")
    
    # í”„ë¦¬ì…‹ í™•ì¸ ë° ì£¼ì œ ì„¤ì •
    topic = get_preset_topic(args.topic)
    
    config = ResearchConfig(
        topic=topic,
        search_queries_count=args.queries,
        word_count_range=word_range,
        language=args.language,
        report_type=args.type,
        quality_mode=args.quality
    )
    
    print(f"ğŸ¯ ì—°êµ¬ ì£¼ì œ: {config.topic}")
    print(f"ğŸ“Š ë³´ê³ ì„œ ìœ í˜•: {config.report_type}")
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {config.search_queries_count}ê°œ")
    print(f"ğŸ“ ëª©í‘œ ë‹¨ì–´ ìˆ˜: {config.word_count_range[0]}-{config.word_count_range[1]}ë‹¨ì–´")
    print(f"ğŸŒŸ í’ˆì§ˆ ëª¨ë“œ: {config.quality_mode}")
    
    # ë¦¬ì„œì¹˜ ì‹¤í–‰
    crew = UnifiedResearchCrew(config)
    result = crew.research()
    
    if result:
        print(f"\nâœ… '{config.topic}' ì—°êµ¬ ë³´ê³ ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print(f"\nâŒ ì‘ì—… ì‹¤íŒ¨. ë¡œê·¸ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")

def run_default():
    """ê¸°ë³¸ ì‹¤í–‰ í•¨ìˆ˜ - CLI ì—†ì´ ë°”ë¡œ ë™ì‘"""
    print("ğŸš€ í†µí•© AI ë¦¬ì„œì¹˜ í¬ë£¨ ì‹œì‘!")
    print("ğŸ“‹ ê¸°ë³¸ ì£¼ì œë¡œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    
    # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì—°êµ¬ ì‹¤í–‰
    config = ResearchConfig(
        topic="2025ë…„ ìµœì‹  AI íŠ¸ë Œë“œ",
        search_queries_count=5,
        word_count_range=(700, 900),
        language="í•œêµ­ì–´",
        report_type="ë¸”ë¡œê·¸",
        quality_mode="korean_optimized"  # í•œêµ­ì–´ ìµœì í™” ëª¨ë“œë¡œ ê¸°ë³¸ ì„¤ì •
    )
    
    print(f"ğŸ¯ ì—°êµ¬ ì£¼ì œ: {config.topic}")
    print(f"ğŸ“Š ë³´ê³ ì„œ ìœ í˜•: {config.report_type}")
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {config.search_queries_count}ê°œ")
    print(f"ğŸ“ ëª©í‘œ ë‹¨ì–´ ìˆ˜: {config.word_count_range[0]}-{config.word_count_range[1]}ë‹¨ì–´")
    print(f"ğŸŒŸ í’ˆì§ˆ ëª¨ë“œ: {config.quality_mode}")
    print("\n" + "="*60)
    
    # ë¦¬ì„œì¹˜ ì‹¤í–‰
    crew = UnifiedResearchCrew(config)
    result = crew.research()
    
    if result:
        print(f"\nâœ… '{config.topic}' ì—°êµ¬ ë³´ê³ ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ ë‹¤ë¥¸ ì£¼ì œë¡œ ì—°êµ¬í•˜ë ¤ë©´: python unified_research_crew.py --topic 'ì›í•˜ëŠ” ì£¼ì œ'")
        print("ğŸ’¡ í•œêµ­ì–´ ìµœì í™” ëª¨ë“œ: python unified_research_crew.py --quality korean_optimized")
    else:
        print(f"\nâŒ ì‘ì—… ì‹¤íŒ¨. ë¡œê·¸ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")
    
    return result

if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ìê°€ ìˆìœ¼ë©´ CLI ëª¨ë“œ, ì—†ìœ¼ë©´ ê¸°ë³¸ ì‹¤í–‰
    if len(sys.argv) > 1:
        main()
    else:
        run_default()

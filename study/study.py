import os
import time
import logging
import requests
from datetime import datetime
from contextlib import contextmanager
import litellm
from crewai import Agent, Task, Crew, Process
from crewai.tools import tool
from dotenv import load_dotenv

# DuckDuckGo Search ì¶”ê°€
try:
    from ddgs import DDGS  # ìƒˆ íŒ¨í‚¤ì§€ëª…
except ImportError:
    from duckduckgo_search import DDGS  # ê¸°ì¡´ íŒ¨í‚¤ì§€ëª… (fallback)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'crewai_dynamic_{datetime.now().strftime("%Y%m%d")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í¬ë£¨ AI í…”ë ˆë©”íŠ¸ë¦¬ ë¹„í™œì„±í™”
os.environ.setdefault("OTEL_SDK_DISABLED", "true")
os.environ.setdefault("CREWAI_DISABLE_TELEMETRY", "true")

# í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸° (ë˜ëŠ” ì§ì ‘ ì„¤ì •)
MODEL_NAME = os.getenv("DEFAULT_LLM", "cpatonn/Devstral-Small-2507-AWQ")
API_BASE_URL = os.getenv("DEFAULT_URL", "http://localhost:54321")
API_KEY = os.getenv("DEFAULT_API_KEY", "huntr/x_How_It's_Done")
TIMEOUT = int(os.getenv("TIMEOUT", "30"))
MAX_EXECUTION_TIME = int(os.getenv("MAX_EXECUTION_TIME", "600")) # ì‹¤í–‰ ì‹œê°„ ì¦ê°€

# URL ì •ê·œí™”
if not API_BASE_URL.endswith('/v1'):
    API_BASE_URL = API_BASE_URL.rstrip('/') + '/v1'

# ===== ì›¹ ê²€ìƒ‰ íˆ´ (ë³€ê²½ ì—†ìŒ) =====
@tool("Web Search Tool")
def web_search_tool(query: str) -> str:
    """
    ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. ìµœì‹  ì •ë³´ë‚˜ íŠ¸ë Œë“œë¥¼ ì°¾ì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        query: ê²€ìƒ‰í•  í‚¤ì›Œë“œë‚˜ ì§ˆë¬¸ (ì˜ˆ: "2025ë…„ AI íŠ¸ë Œë“œ", "ìµœì‹  ìƒì„±í˜• AI ë°œì „ì‚¬í•­")
    
    Returns:
        str: ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡ (ì œëª©, ì„¤ëª…, ë§í¬ í¬í•¨)
    """
    try:
        logger.info(f"ì›¹ ê²€ìƒ‰ ì‹œì‘: '{query}'")
        ddgs = DDGS()
        results = ddgs.text(
            query=query, 
            region='wt-wt',
            safesearch='moderate', 
            max_results=5
        )
        if not results:
            return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        formatted_results = f"ğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼:\n\n"
        for i, result in enumerate(results, 1):
            title = result.get('title', 'ì œëª© ì—†ìŒ')
            body = result.get('body', 'ì„¤ëª… ì—†ìŒ')
            href = result.get('href', '#')
            
            formatted_results += f"{i}. **{title}**\n"
            formatted_results += f"   ğŸ“„ {body[:200]}{'...' if len(body) > 200 else ''}\n"
            formatted_results += f"   ğŸ”— {href}\n\n"
        
        logger.info(f"ì›¹ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼ ë°˜í™˜")
        return formatted_results
        
    except Exception as e:
        error_msg = f"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        return error_msg

# ===== ê¸°ì¡´ í•¨ìˆ˜ë“¤ (ë³€ê²½ ì—†ìŒ) =====
def retry_with_backoff(func, max_retries=3, base_delay=1):
    for attempt in range(max_retries):
        try:
            return func()
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
            delay = base_delay * (2 ** attempt)
            logger.warning(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}. {delay}ì´ˆ í›„ ì¬ì‹œë„...")
            time.sleep(delay)

@contextmanager
def managed_session():
    session = requests.Session()
    try:
        yield session
    finally:
        session.close()

def test_litellm_connection():
    def _test():
        logger.info("LiteLLM ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
        response = litellm.completion(
            model=f"openai/{MODEL_NAME}",
            messages=[{"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”, LiteLLM í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤."}],
            api_base=API_BASE_URL,
            api_key=API_KEY,
            temperature=0.7,
            max_tokens=100,
            timeout=TIMEOUT,
            drop_params=True
        )
        test_content = response.choices[0].message.content
        logger.info(f"LiteLLM í…ŒìŠ¤íŠ¸ ì„±ê³µ: {test_content}")
        return True
    return retry_with_backoff(_test)

def test_web_search():
    try:
        logger.info("ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")
        test_result = web_search_tool.func("AI íŠ¸ë Œë“œ 2025")
        if "ê²€ìƒ‰ ê²°ê³¼" in test_result or "ì˜¤ë¥˜" in test_result:
            logger.info("âœ… ì›¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            return True
        else:
            logger.warning("âš ï¸ ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤")
            return False
    except Exception as e:
        logger.error(f"âŒ ì›¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def setup_litellm_global_config():
    litellm.api_base = API_BASE_URL
    litellm.api_key = API_KEY
    litellm.drop_params = True
    os.environ['LITELLM_LOG'] = 'INFO'
    logger.info("LiteLLM ì „ì—­ ì„¤ì • ì™„ë£Œ")

# ===== [ìˆ˜ì • ì—†ìŒ] ì—ì´ì „íŠ¸ ìƒì„± í•¨ìˆ˜ =====
def create_agents():
    """
    ë™ì  ê²€ìƒ‰ì„ ìœ„í•œ ì—ì´ì „íŠ¸ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
    - `planner`: ì—°êµ¬ ì£¼ì œë¥¼ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ê³„íš(ì¿¼ë¦¬ ëª©ë¡)ì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.
    - `researcher`: ê³„íšì— ë”°ë¼ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ì •ë³´ë¥¼ ì¢…í•©í•©ë‹ˆë‹¤.
    - `writer`: ì¢…í•©ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•©ë‹ˆë‹¤.
    """
    
    # ìƒˆë¡œìš´ ì—ì´ì „íŠ¸: ì—°êµ¬ ê³„íšì
    planner = Agent(
        role='ì—°êµ¬ ê³„íš ì „ë¬¸ê°€',
        goal='ì£¼ì–´ì§„ ì—°êµ¬ ì£¼ì œë¥¼ ë¶„ì„í•˜ì—¬ íš¨ê³¼ì ì¸ ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ ëª©ë¡ì„ ìƒì„±',
        backstory='''ë‹¹ì‹ ì€ ë³µì¡í•œ ì£¼ì œë¥¼ í•µì‹¬ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ë° ëŠ¥ìˆ™í•œ ì „ëµê°€ì…ë‹ˆë‹¤. 
        ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ì—°êµ¬ ë¶„ì„ê°€ê°€ ìµœìƒì˜ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ ëª…í™•í•˜ê³  ê°„ê²°í•œ ê²€ìƒ‰ ê³„íšì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.''',
        verbose=True,
        allow_delegation=False,
        llm=f"openai/{MODEL_NAME}",
        max_tokens=1024,
        temperature=0.6
    )

    # ê¸°ì¡´ ì—°êµ¬ ë¶„ì„ê°€ (ì—­í•  ì¬ì •ì˜)
    researcher = Agent(
        role='ê³ ê¸‰ ì—°êµ¬ ë¶„ì„ê°€',
        goal='ì œê³µëœ ê²€ìƒ‰ ê³„íšì— ë”°ë¼ ìµœì‹  AI íŠ¸ë Œë“œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ì¢…í•©ì ì¸ ë³´ê³ ì„œ ì‘ì„±',
        backstory='''ë‹¹ì‹ ì€ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì‹¤ì‹œê°„ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì—¬ëŸ¬ ì¶œì²˜ì˜ ì •ë³´ë¥¼ ë¹„íŒì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ 
        í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ëŠ” ë° íŠ¹í™”ëœ ìˆ™ë ¨ëœ ì—°êµ¬ì›ì…ë‹ˆë‹¤.''',
        verbose=True,
        allow_delegation=False,
        tools=[web_search_tool],
        llm=f"openai/{MODEL_NAME}",
        max_tokens=2000,
        temperature=0.7
    )

    # ê¸°ì¡´ ì „ë¬¸ ì‘ê°€ (ë³€ê²½ ì—†ìŒ)
    writer = Agent(
        role='ì „ë¬¸ ì½˜í…ì¸  ì‘ê°€',
        goal='ì£¼ì–´ì§„ ì—°êµ¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤ë ¥ì ì¸ ë¸”ë¡œê·¸ ê²Œì‹œë¬¼ ì‘ì„±',
        backstory='''ë…ìë“¤ì—ê²Œ ë³µì¡í•œ ê°œë…ì„ ëª…í™•í•˜ê³  ë§¤ë ¥ì ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ë° ë›°ì–´ë‚œ ì‘ê°€ì…ë‹ˆë‹¤.
        ìµœì‹  ì •ë³´ì™€ íŠ¸ë Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì‹¤ì ì´ê³  ìœ ìš©í•œ ì½˜í…ì¸ ë¥¼ ë§Œë“­ë‹ˆë‹¤.''',
        verbose=True,
        allow_delegation=False,
        llm=f"openai/{MODEL_NAME}",
        max_tokens=2000,
        temperature=0.8
    )
    
    return planner, researcher, writer

# ===== [ìˆ˜ì •ë¨] ì‘ì—… ìƒì„± í•¨ìˆ˜ =====
def create_tasks(planner, researcher, writer):
    """
    ë™ì  ê²€ìƒ‰ì„ ìœ„í•œ ì‘ì—…ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    
    # 1. ì—°êµ¬ ì£¼ì œë¥¼ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” ì‘ì—…
    planning_task = Task(
        description='''2025ë…„ ìµœì‹  AI íŠ¸ë Œë“œì— ëŒ€í•œ í¬ê´„ì ì¸ ì—°êµ¬ë¥¼ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.
        ì´ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´, ê°€ì¥ ì¤‘ìš”í•˜ê³  ê´€ë ¨ì„± ë†’ì€ í•˜ìœ„ ì£¼ì œë“¤ì„ ì‹ë³„í•˜ì„¸ìš”.

        ë‹¤ìŒ ì˜ì—­ì„ ê³ ë ¤í•˜ì—¬ 4~5ê°œì˜ êµ¬ì²´ì ì´ê³  íš¨ê³¼ì ì¸ ì˜ì–´ ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”:
        - ìƒì„±í˜• AI (Generative AI)ì˜ ìµœì‹  ë°œì „
        - ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ (LLM)ì˜ ìƒˆë¡œìš´ ê¸°ëŠ¥ ë˜ëŠ” ì•„í‚¤í…ì²˜
        - AI ìœ¤ë¦¬ ë° ê·œì œ ë™í–¥
        - ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œì˜ AI ì ìš© ì‚¬ë¡€
        
        ê° ì¿¼ë¦¬ëŠ” ëª…í™•í•˜ê³  ë…ë¦½ì ìœ¼ë¡œ ê²€ìƒ‰ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.''',
        
        expected_output='''ì—°êµ¬ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ 4~5ê°œì˜ ì˜ì–´ ê²€ìƒ‰ ì¿¼ë¦¬ ëª©ë¡.
        ê° ì¿¼ë¦¬ëŠ” í•œ ì¤„ë¡œ ëª…í™•í•˜ê²Œ êµ¬ë¶„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: `- "query"` í˜•ì‹)
        ì˜ˆì‹œ:
        - "latest breakthroughs in multimodal generative AI 2025"
        - "new architectures for large language models 2025"
        - "global AI ethics and regulation policies 2025"
        - "AI applications in healthcare industry 2025 case studies"
        ''',
        agent=planner
    )
    
    # 2. ìƒì„±ëœ ê³„íšì— ë”°ë¼ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ìš”ì•½í•˜ëŠ” ì‘ì—…
    research_task = Task(
        description='''[ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ëª©ë¡]ì„ í™œìš©í•˜ì—¬ 2025ë…„ ìµœì‹  AI íŠ¸ë Œë“œì— ëŒ€í•œ ì‹¬ì¸µ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³ , 
        ì£¼ìš” ë°œê²¬ ì‚¬í•­ì„ ì¢…í•©ì ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.

        **ìˆ˜í–‰ ì ˆì°¨:**
        1. ì´ì „ Taskì˜ ê²°ê³¼ë¬¼ì—ì„œ ì œê³µëœ **ê°ê°ì˜ ê²€ìƒ‰ ì¿¼ë¦¬(ì˜ˆ: `- "query"` í˜•ì‹)**ë¥¼ ì •í™•íˆ ì¶”ì¶œí•©ë‹ˆë‹¤.
        2. ì¶”ì¶œëœ **ëª¨ë“  ì¿¼ë¦¬ì— ëŒ€í•´** 'Web Search Tool'ì„ **ìˆœì„œëŒ€ë¡œ ê°œë³„ì ìœ¼ë¡œ ì‚¬ìš©**í•©ë‹ˆë‹¤.
           ê° ê²€ìƒ‰ í›„ì—ëŠ” ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³ , ë‹¤ìŒ ì¿¼ë¦¬ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
           ì˜ˆì‹œ:
           Thought: ì²« ë²ˆì§¸ ì¿¼ë¦¬ "latest breakthroughs in multimodal generative AI 2025"ë¡œ ê²€ìƒ‰í•´ì•¼ê² ë‹¤.
           Action: Web Search Tool
           Action Input: {"query": "latest breakthroughs in multimodal generative AI 2025"}
           Observation: (ê²€ìƒ‰ ê²°ê³¼)
           Thought: ì´ì œ ë‘ ë²ˆì§¸ ì¿¼ë¦¬ "new architectures for large language models 2025"ë¡œ ê²€ìƒ‰í•´ì•¼ê² ë‹¤.
           Action: Web Search Tool
           Action Input: {"query": "new architectures for large language models 2025"}
           Observation: (ê²€ìƒ‰ ê²°ê³¼)
           ... ì´ëŸ° ë°©ì‹ìœ¼ë¡œ **ëª¨ë“  ì¿¼ë¦¬ë¥¼ ì†Œì§„**í•  ë•Œê¹Œì§€ ë°˜ë³µí•©ë‹ˆë‹¤.
        3. ëª¨ë“  ê²€ìƒ‰ì´ ì™„ë£Œë˜ë©´, ìˆ˜ì§‘ëœ **ëª¨ë“  ì •ë³´**ë¥¼ ë¹„íŒì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆê³  ìµœì‹  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬
           í•µì‹¬ì ì¸ ì¸ì‚¬ì´íŠ¸, ìµœì‹  í†µê³„, ê·¸ë¦¬ê³  êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ í¬í•¨í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
           (ì£¼ì˜: ê²€ìƒ‰ ê²°ê³¼ëŠ” ì˜ì–´ì¼ ìˆ˜ ìˆìœ¼ë‚˜, ë³´ê³ ì„œëŠ” í•œêµ­ì–´ë¡œ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.)
        4. ë³´ê³ ì„œëŠ” ì£¼ìš” íŠ¸ë Œë“œë³„ë¡œ êµ¬ì¡°í™”í•˜ì—¬ ì •ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.

        ëª¨ë“  ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆëŠ”ì§€ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•˜ì„¸ìš”.
        ''',
        
        expected_output='''2025ë…„ AI íŠ¸ë Œë“œì— ëŒ€í•œ ì£¼ìš” í†µì°°ë ¥, ìµœì‹  í†µê³„ ë° ì‹¤ì œ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ëŠ” 
        400-500ë‹¨ì–´ ë¶„ëŸ‰ì˜ ìƒì„¸í•œ ì—°êµ¬ ìš”ì•½ ë³´ê³ ì„œ (í•œêµ­ì–´).
        **ë™ì ìœ¼ë¡œ ìƒì„±ëœ ëª¨ë“  ì¿¼ë¦¬**ë¥¼ í†µí•´ ì–»ì€ ìµœì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.''',
        
        agent=researcher,
        context=[planning_task]  # planning_taskì˜ ê²°ê³¼(ê²€ìƒ‰ì–´ ëª©ë¡)ë¥¼ ì´ taskì˜ contextë¡œ ì‚¬ìš©
    )

    # 3. ì—°êµ¬ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•˜ëŠ” ì‘ì—…
    write_task = Task(
        description='''ì—°êµ¬ ìš”ì•½ ë³´ê³ ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ "2025ë…„ AI í˜ëª…: í˜„ì‹¤ì´ ëœ ë¯¸ë˜ ê¸°ìˆ ë“¤"ì´ë¼ëŠ” 
        ì œëª©ì˜ í•œêµ­ì–´ ë¸”ë¡œê·¸ ê²Œì‹œë¬¼ì„ ì‘ì„±í•©ë‹ˆë‹¤.
        
        **ë§¤ìš° ì¤‘ìš”:** ëª¨ë“  ë‚´ìš©ì€ **í•œêµ­ì–´**ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì—°êµ¬ ë³´ê³ ì„œ ë‚´ìš© ì¤‘ ì˜ì–´ í‘œí˜„ì´ ìˆë‹¤ë©´, 
        ì´ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì—¬ ë³¸ë¬¸ì— í¬í•¨ì‹œí‚¤ì„¸ìš”.
        
        ìš”êµ¬ì‚¬í•­:
        - 700-900ë‹¨ì–´ ë¶„ëŸ‰
        - ë§¤ë ¥ì ì¸ ë„ì…ë¶€ì™€ ê²°ë¡ 
        - ì—°êµ¬ ë³´ê³ ì„œì˜ ìµœì‹  ì •ë³´ë¥¼ ë°˜ì˜í•œ í˜„ì‹¤ì ì¸ ë‚´ìš©
        - ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´ ì‚¬ìš©
        - ë…ìì˜ ê´€ì‹¬ì„ ë„ëŠ” ë¶€ì œëª© í™œìš©
        - 2025ë…„ í˜„ì¬ ìƒí™©ì„ ë°˜ì˜í•œ ì‹¤ì œ ì‚¬ë¡€ë‚˜ ì˜ˆì‹œ í¬í•¨
        
        ëŒ€ìƒ ë…ì: AIì— ê´€ì‹¬ìˆëŠ” ì¼ë°˜ ëŒ€ì¤‘ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€''',
        
        expected_output='''ë…ìì˜ ì°¸ì—¬ë¥¼ ìœ ë„í•˜ê³  ì •ë³´ê°€ í’ë¶€í•˜ë©° ì˜ êµ¬ì„±ëœ 700-900ë‹¨ì–´ ë¶„ëŸ‰ì˜ 
        ë¸”ë¡œê·¸ ê²Œì‹œë¬¼. ëª¨ë“  ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°, ë™ì  ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°˜ì˜í•œ 
        í˜„ì‹¤ì ì´ê³  ìœ ìš©í•œ ë‚´ìš© í¬í•¨.''',
        
        agent=writer,
        context=[research_task]
    )
    
    return planning_task, research_task, write_task

def save_result(result):
    """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    if not result:
        logger.warning("ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
        
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"ai_trends_blog_dynamic_search_{timestamp}.md"
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"# AI íŠ¸ë Œë“œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ (ë™ì  ì›¹ ê²€ìƒ‰ í™œìš©)\n")
            f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ê²€ìƒ‰ ê¸°ëŠ¥: DuckDuckGo (ë™ì  ì¿¼ë¦¬ ìƒì„±)\n\n")
            f.write("---\n\n")
            f.write(str(result))
        
        logger.info(f"ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return filename
    except Exception as e:
        logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

# ===== [verbose=Trueë¡œ ìˆ˜ì •ë¨] Crew ì‹¤í–‰ í•¨ìˆ˜ =====
def run_crew_with_error_handling():
    """ì—ëŸ¬ ì²˜ë¦¬ê°€ í¬í•¨ëœ í¬ë£¨ ì‹¤í–‰ í•¨ìˆ˜ (ë™ì  ì›¹ ê²€ìƒ‰ í¬í•¨)"""
    try:
        logger.info("=" * 60)
        logger.info("ğŸš€ CrewAI with Dynamic Web Search ì‹œì‘")
        logger.info("=" * 60)
        
        # ì„¤ì • ê²€ì¦ ë° ì—°ê²° í…ŒìŠ¤íŠ¸
        logger.info(f"ëª¨ë¸: {MODEL_NAME}, API Base: {API_BASE_URL}")
        test_litellm_connection()
        test_web_search()
        setup_litellm_global_config()
        
        # ì—ì´ì „íŠ¸ ë° ì‘ì—… ìƒì„±
        logger.info("\nğŸ“ ì—ì´ì „íŠ¸ ë° ì‘ì—… ì„¤ì • ì¤‘...")
        planner, researcher, writer = create_agents()
        planning_task, research_task, write_task = create_tasks(planner, researcher, writer)
        
        # í¬ë£¨ ìƒì„± ë° ì‹¤í–‰
        crew = Crew(
            agents=[planner, researcher, writer],
            tasks=[planning_task, research_task, write_task],
            process=Process.sequential,
            verbose=True, # âœ… ì´ ë¶€ë¶„ì„ Trueë¡œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
            max_execution_time=MAX_EXECUTION_TIME
        )
        
        logger.info("\n" + "=" * 60)
        logger.info("ğŸš€ AI í¬ë£¨ ì‘ì—… ì‹œì‘ (ë™ì  ì›¹ ê²€ìƒ‰)")
        logger.info("ì˜ˆìƒ ì†Œìš” ì‹œê°„: 3-5ë¶„ (ê³„íš ìˆ˜ë¦½ ë° ë‹¤ì¤‘ ê²€ìƒ‰ í¬í•¨)")
        logger.info("=" * 60)
        
        result = crew.kickoff()
        
        # ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥
        saved_file = save_result(result)
        
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ í¬ë£¨ ì‘ì—… ì™„ë£Œ!")
        logger.info("=" * 60)
        print("\nğŸ“„ ìƒì„±ëœ ì½˜í…ì¸ :")
        print("=" * 80)
        print(result)
        print("=" * 80)
        
        if saved_file:
            logger.info(f"\nğŸ“ ê²°ê³¼ê°€ '{saved_file}' íŒŒì¼ì—ë„ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            logger.info("ğŸ’¡ ì´ íŒŒì¼ì—ëŠ” ì—ì´ì „íŠ¸ê°€ ë™ì ìœ¼ë¡œ ìƒì„±í•œ ê²€ìƒ‰ì–´ë¥¼ í†µí•´ ìˆ˜ì§‘ëœ ìµœì‹  ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ í¬ë£¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        logger.info("\nğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²• ì œì•ˆ:")
        logger.info("1. `pip install --upgrade crewai crewai-tools duckduckgo-search` ë¡œ ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.")
        logger.info("2. ë¡œì»¬ API ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        logger.info("3. .env íŒŒì¼ì˜ ëª¨ë¸ ì´ë¦„, API ì£¼ì†Œ, API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        logger.info("4. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        logger.info("5. ë¡œê·¸ íŒŒì¼ì„ í†µí•´ ìƒì„¸í•œ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”.")
        return None

# ì‹¤í–‰
if __name__ == "__main__":
    try:
        import duckduckgo_search
        logger.info("âœ… duckduckgo-search íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    except ImportError:
        logger.error("âŒ duckduckgo-search íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        logger.info("ğŸ’¡ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install duckduckgo-search")
        exit(1)
    
    result = run_crew_with_error_handling()
    
    if result:
        print("\nâœ… ë™ì  ì›¹ ê²€ìƒ‰ì„ í¬í•¨í•œ AI ë¸”ë¡œê·¸ ìƒì„±ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ğŸ” ì´ì œ ì—¬ëŸ¬ë¶„ì˜ AI íŒ€ì´ ìŠ¤ìŠ¤ë¡œ ê³„íšì„ ì„¸ìš°ê³  ì‹¤ì‹œê°„ ì •ë³´ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•´ë³´ì„¸ìš”.")